# Self-Organizing Map (SOM) for Iris Dataset Clustering

This report details the application of a Self-Organizing Map (SOM) to cluster the Iris dataset.  The SOM is an unsupervised neural network that projects high-dimensional data onto a lower-dimensional grid, facilitating visualization and clustering.
![reSult](https://github.com/user-attachments/assets/2921751e-2461-4cc9-9506-95e7c78d76a7)

## 1. Data Loading and Exploration

The Iris dataset, containing measurements of sepal and petal lengths and widths for three species of iris flowers (setosa, versicolor, and virginica), is loaded using `sklearn.datasets`.  A Pandas DataFrame is created for easier manipulation and analysis.

Initial data exploration is performed:

*   The first few rows are printed using `head()`.
*   Data types are checked using `dtypes`.
*   Missing values are checked using `isnull().sum()`.
*   Descriptive statistics are displayed using `describe()`.

This initial exploration ensures data integrity and provides a basic understanding of the dataset's characteristics.

## 2. Data Preprocessing

Data standardization is performed using `StandardScaler` from `sklearn.preprocessing`.  Only the feature columns (sepal and petal measurements) are standardized, ensuring that all features have zero mean and unit variance.  This is crucial for SOM performance, as it prevents features with larger ranges from dominating the clustering process.

## 3. SOM Design and Implementation

A `MiniSom` object is initialized with the following parameters:

*   `som_x`, `som_y`: Dimensions of the SOM grid (10x10 in this case).
*   `input_len`: Number of input features (4 for the Iris dataset).
*   `sigma`: Initial neighborhood radius.
*   `learning_rate`: Learning rate for the SOM training process.

The SOM weights are initialized randomly, and the training process is performed using `som.train_random`.  The `num_iterations` parameter controls the number of training epochs.

## 4. Data Clustering using SOM

After training, each data point is mapped to its Best Matching Unit (BMU) or winner neuron on the SOM grid using `som.winner(d)`.  The `win_map` function retrieves all the data points associated with each neuron.  A new 'cluster' column is added to the Iris DataFrame, storing the coordinates of the BMU for each data point in the format "x-y".

## 5. Analysis and Visualization

### 5.1. SOM Cluster Plotting

A scatter plot visualizes the clusters.  The x and y coordinates of the data points are plotted, and each point is colored according to its original Iris species label.  This allows for visual inspection of how well the SOM clusters correspond to the actual species.

### 5.2. Cluster Counts

The number of data points in each cluster is calculated and printed using `value_counts()`. This helps understand the distribution of data across the SOM grid.

### 5.3. Clustering Evaluation

To evaluate the clustering quality, a mapping between SOM clusters and the original Iris species is established.  For each cluster, the most frequent species among the data points assigned to that cluster is determined using the mode.  This mapping is stored in the `label_map` dictionary.

Predicted labels are then generated by looking up the cluster assignment for each data point in the `label_map`.  The `accuracy_score` and `confusion_matrix` from `sklearn.metrics` are used to evaluate the performance of the clustering by comparing the predicted labels with the true labels (Iris species).

## 6. Results

The report includes the generated plots, cluster counts, clustering accuracy, and confusion matrix. The visualization provides a qualitative assessment of the clustering, while the accuracy and confusion matrix offer a quantitative measure of performance.

## 7. Discussion

This report demonstrates the use of SOM for clustering the Iris dataset. The SOM effectively projects the 4-dimensional data onto a 2-dimensional grid, allowing for visualization and identification of clusters. The evaluation metrics provide insights into the clustering performance.

Potential improvements include:

*   Tuning SOM parameters (`som_x`, `som_y`, `sigma`, `learning_rate`, `num_iterations`) to optimize the clustering results.
*   Exploring different visualization techniques to better understand the SOM structure and data distribution.
*   Applying other clustering evaluation metrics, such as silhouette score or Davies-Bouldin index.
*   Comparing the SOM results with other clustering algorithms, such as k-means or hierarchical clustering.
*   Applying the SOM to other high-dimensional datasets to test its generalizability.

This report provides a comprehensive analysis of the SOM application for Iris dataset clustering.  The code serves as a practical example of using SOM for dimensionality reduction and clustering.
